env:
  id: "Env.env"
  user_nums: 20
  sector_nums: 3
  agent_nums: 3
  bs_antenna_nums: 16
  total_antenna_nums: 20
  sliding_windows_length: 1000
  transmit_power: 0.25
  noise_power: 
  source_data_folder: data_part/Source_data
  save_data_folder:
  velocity: 30
  subcarrier_nums: 50
  traning_data_total_TT_length: 10000
  eval_data_total_TTI_length: 1000
  delay_time_window: 200

# 要不要保存上一次训练得到的历史队列
use_history: fasle
# learning rate 为0的时间,用于优化器的初始化
warmup_time: 10
# ip of log server, config_server
main_server_ip: '10.15.89.154'
# 定义日志文件的文件夹
log_dir: "./logs"
# 定义日志服务器的端口
log_server_port: 8100
# 这个表示的是新模型通过tcp下载更新
p2p: true
# 这个表示的是将历史的模型保存20个
p2p_cache_size: 20
# 多久保存一次模型到p2p_path
latest_update_interval: 15
# 这两个端口分别表示,worker请求的端口,以及learner将模型通过哪一个端口发布出去
config_server_request_model_port: 9000
config_server_model_update_port: 9001
# 主模型更新时间间隔
sampler_model_update_interval: 20
# learner related
learners:
  policy_id: max_average_SE
  # 这个config下对应的模型名称
  model_name: 'attention_model'
  # 定义训练机器的ip列表
  machines: ['10.15.89.154']
  # 定义主机索引, 每台机器有多少张卡, 每个卡对应多少个数据服务
  main_machine_index: 0
  gpu_num_per_machine: 4
  data_server_to_learner_num: 8
  # 模型相关
  batch_size: 2048
  gamme: 0.997
  tau: 0.95
  ppo_clip: 0.2
  grad_clip: 10
  dual_clip: 3
  lr: 0.00001
  entropy_coef: 0.01
  # 环境相关
  env_count: 1000
  traj_len: 300
  n_sample: 1
  # Pytorch DDP相关
  ddp_port: 50001
  # 暴露给其他learner进程的监听端口
  root_gpu_pub_star_port: 6500
  # 暴露给sampler的监听端口
  learner_port_start: 7500
  fetch_policy: 'latest'
  load_model: 0
  config_server_delay_update_interval: 300
  model_path: "save_model/pointer_network/max_average_SE"
  
  # env related，通过另外一个yaml文件更新得到的


