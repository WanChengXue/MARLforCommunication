env:
  id: "Env.Single_cell_env"
  user_nums: 20
  sector_nums: &sense_channel_nums 3
  cell_nums: 1
  agent_nums: &agent_nums 1
  bs_antenna_nums: &bs_antenna_nums 16
  total_antenna_nums: &seq_len 20
  # 这个变量表示的是截取多少长度的TTI作为一个训练样本
  sliding_windows_length: 400
  transmit_power: 0.25
  noise_power: 3.1623e-20
  source_data_folder: 'data_part/Source_data'
  save_data_folder: 'data_part/preprocess_data'
  demonstration_data_folder: 'data_part/demonstration_data/single_cell_scenario'
  velocity: 30
  sub_carrier_nums: 50
  # 最大流的数目小于等于发射天线的数目
  max_stream_nums: *bs_antenna_nums 
  min_stream_nums: &min_decoder_time 3
  # 这个是值表示的是一个信道文件总共有多少个TTI
  training_data_total_TTI_length: 10000
  # 这个值表示的滑窗的长度Ts
  delay_time_window: 200
  min_user_average_se: 0.08
  # ----------- 在探索阶段，有些用户的分母会很小，当所有的用户都探索了一次之后，才不会有单个用户PF最大为0.25的限制 -----------
  max_user_pf_value: 2
  parallel_env: 1000
  one_step_env: True
  replay_buffer_name: 'TrainingSet_one_step_single_cell'
policy_name: single_cell_max_se_ddpg
# 要不要保存上一次训练得到的历史队列
use_history: fasle
# learning rate 为0的时间,用于优化器的初始化
warmup_time: 0
# ip of log server, config_server
main_server_ip: '10.19.93.9'
# 定义日志文件的文件夹
log_dir: "./logs"
# 定义日志服务器的端口
log_server_port: 8100
# 这个表示的是将历史的模型保存20个
model_cache_size: 10
# 这两个端口分别表示,worker请求的端口,以及learner将模型通过哪一个端口发布出去
config_server_model_from_learner: 9000
config_server_model_to_worker: 9001
# 主模型更新时间间隔,这个变量主要是worker端使用，没隔20s调用一次fetcher从config server获取一次最新的模型 -------
sampler_model_update_interval: 20
# ----------- configserver打开http的端口 -----------
config_server_http_port: 9002
# ========== learner related ==============
# ----- 这个变量是learner端使用，表示发布新模型的时间间隔 -----
model_update_intervel: 3
# --------- 这个变量是dataserver是从buffer里面采一个batch的数据放入到plasma client里面的时间间隔 -----------------
data_server_sampling_interval: 0 
# policy_config related
policy_config:
  # 这个config下对应的模型名称
  # 定义训练机器的ip列表
  main_machine_index: 0
  machine_list: ['10.19.93.9']
  # 定义一个设备对应与多少个数据server
  server_number_per_device: 2
  # 定义一个机器有多少个设备
  device_number_per_machine: 1
  start_data_server_port: 9527
  eval_mode: False
  # ---------- 策略相关 ------
  policy_type: 'latest'
  algorithm: 'ddpg'
  using_target_network: True
  # Pytorch DDP相关
  ddp_port: 50001
  batch_size: &batch_size 2048
  gamma: 0.997
  tau: 0.95
  # ------- 使用wolpagent --------
  using_wolpagent: True
  # ------- 和demonstration data相关 ------
  demonstration_threshold: 0.0
  # -------------- 模型训练相关 --------------
  training_parameters:
    clip_epsilon: 0.2
    max_grad_norm: 10
    dual_clip: 2
    entropy_coef: 0.01
    agent_nums: *agent_nums
    multi_objective_start: &multi_objective_start False
    popart_start: &popart_start False
    seperate_critic: &seperate_critic True
  # 环境相关
  traj_len: 32
  capacity: &capacity 50000
  # -------- 每训练1000次就保存一下模型 ----------
  model_save_interval: 1000
  # ------- 每训练10次就评估一下模型 --------
  evaluate_model_interval: 10
  # ------ 设置模型的保存路径 ——----------
  # ======= 两个路径一个是最新的模型构成的模型池，另外一个是每训练若干次保存下来的模型 =====
  model_pool_path: "Exp/Model/model_pool/"
  saved_model_path: "Exp/Model/saved_model/"
  tensorboard_folder: "Tensorboard_log"
  # ----- 只有一个智能体，显然是参数共享和同质化都是True ---------
  parameter_sharing: &parameter_sharing True
  homogeneous_agent: True
  # ------ 这个地方采用的cosineannealingwarmrestarts()学习率调整 ------------
  T_zero: 20
  # plasma相关
  plasma_server_location: Plasma_server/plasma
  # ------ centralize_critic表示采用中心化的critic，seperate_critic表示每一个智能体都有一个critic
  seperate_critic: *seperate_critic
  agent:
    # ------- critic的逻辑，如果采用中心化的critic，则另外两个值都是False，如果采用分离critic，则seperate_critic为True，最后一个值可True可False -------
    policy:
      # -------- 策略网络的相关配置 -----------
      default_single_cell:
        learning_rate: 1e-4
        model_name: 'FC_model'
        # ---- model related ----------
        # ------------ 这个32必须是和天线维度一样，天线16根，变成实数就是32
        state_feature_dim: *bs_antenna_nums
        # ---------- hidden_dim是通过数据的预处理之后得到的特征图的维度 ----------
        hidden_dim: &hidden_dim 64
        feature_map_size: &feature_map_size 100
        window_size: [2,3,4,5]
        action_dim: *seq_len
        model_type: 'policy'
        parameter_sharing: *parameter_sharing
      # -------- 状态维度和动作维度由环境直接给出 -----------
    critic:
      # -------- critic网络的相关配置 ---------
      default_single_cell:      
        learning_rate: 1e-4
        model_name: 'FC_model'
        # ------ model_related -----------
        state_feature_dim: *bs_antenna_nums
        hidden_dim: *hidden_dim
        feature_map_size: *feature_map_size
        window_size: [2,3,4,5]
        action_dim: *seq_len
        # ----- 这个变量一旦打开，表示同时优化边缘用户和系统性能 ------------
        model_type: 'critic'
  # --------- replay buffer相关 -----------
  buffer:
    batch_size: *batch_size
    max_decoder_time: *seq_len
    seq_len: *seq_len
    max_capacity: *capacity
    bs_antenna_nums: *bs_antenna_nums
        
        

  
  


